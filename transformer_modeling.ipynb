{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "604d4cb2-0c24-4bf7-b44b-0081ec98aa1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Using cached tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.10.3-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Using cached tokenizers-0.15.0-cp39-cp39-macosx_10_7_x86_64.whl (2.6 MB)\n",
      "Collecting safetensors>=0.3.1\n",
      "  Using cached safetensors-0.4.1-cp39-cp39-macosx_10_7_x86_64.whl (441 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4\n",
      "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.1-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Installing collected packages: tqdm, safetensors, regex, fsspec, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed fsspec-2023.12.1 huggingface-hub-0.19.4 regex-2023.10.3 safetensors-0.4.1 tokenizers-0.15.0 tqdm-4.66.1 transformers-4.35.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e656f7d2-b727-48bc-a5bb-9e500504344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 KB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow-hotfix\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./venv/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./venv/lib/python3.9/site-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.9/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in ./venv/lib/python3.9/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./venv/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Collecting multiprocess\n",
      "  Using cached multiprocess-0.70.15-py39-none-any.whl (133 kB)\n",
      "Collecting pyarrow>=8.0.0\n",
      "  Using cached pyarrow-14.0.1-cp39-cp39-macosx_10_14_x86_64.whl (26.9 MB)\n",
      "Collecting xxhash\n",
      "  Using cached xxhash-3.4.1-cp39-cp39-macosx_10_9_x86_64.whl (31 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.9.1-cp39-cp39-macosx_10_9_x86_64.whl (397 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.9/397.9 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
      "  Using cached fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "Collecting dill<0.3.8,>=0.3.0\n",
      "  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting async-timeout<5.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp39-cp39-macosx_10_9_x86_64.whl (29 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 KB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.4.0-cp39-cp39-macosx_10_9_x86_64.whl (47 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.12.1\n",
      "    Uninstalling fsspec-2023.12.1:\n",
      "      Successfully uninstalled fsspec-2023.12.1\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.15.0 dill-0.3.7 frozenlist-1.4.0 fsspec-2023.10.0 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.1 pyarrow-hotfix-0.6 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4b42a7a-b04a-4a06-b6f8-738e141bfab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.1.1-cp39-none-macosx_10_9_x86_64.whl (147.0 MB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Collecting sympy\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.9/site-packages (from torch) (2023.12.1)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.2.1 sympy-1.12 torch-2.1.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd1a92da-21db-4129-bda4-3903481858e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting scipy>=1.5.0\n",
      "  Using cached scipy-1.11.4-cp39-cp39-macosx_10_9_x86_64.whl (37.3 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./venv/lib/python3.9/site-packages (from scikit-learn) (1.26.2)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.11.4 threadpoolctl-3.2.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6137757d-160b-475d-bc8e-52ea043fc288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.1-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting GitPython!=3.1.29,>=1.0.0\n",
      "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 KB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting setproctitle\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-macosx_10_9_x86_64.whl (11 kB)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: PyYAML in ./venv/lib/python3.9/site-packages (from wandb) (6.0.1)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Click!=8.0.0,>=7.1\n",
      "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (5.9.6)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from wandb) (58.1.0)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0\n",
      "  Downloading protobuf-4.25.1-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in ./venv/lib/python3.9/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from wandb) (4.8.0)\n",
      "Requirement already satisfied: six>=1.4.0 in ./venv/lib/python3.9/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, protobuf, docker-pycreds, Click, gitdb, GitPython, wandb\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.40 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 protobuf-4.25.1 sentry-sdk-1.38.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9d309c2-27ac-40d5-83a5-0823297e2cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.9/site-packages (2.1.1)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.16.1-cp39-cp39-macosx_10_13_x86_64.whl (1.6 MB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.1.1-cp39-cp39-macosx_10_13_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.9/site-packages (from torch) (2023.12.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from torchvision) (2.31.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0\n",
      "  Using cached Pillow-10.1.0-cp39-cp39-macosx_10_10_x86_64.whl (3.5 MB)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->torchvision) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.9/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: pillow, torchvision, torchaudio\n",
      "Successfully installed pillow-10.1.0 torchaudio-2.1.1 torchvision-0.16.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0546bb19-de2e-48ef-957f-b570843faabf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.9/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk) (8.1.7)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66c9be46-3527-4ccf-9ea9-b88c2d989945",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Using cached gensim-4.3.2-cp39-cp39-macosx_10_9_x86_64.whl (24.1 MB)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Using cached smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in ./venv/lib/python3.9/site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in ./venv/lib/python3.9/site-packages (from gensim) (1.11.4)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ff4f508d-f567-46e9-8f60-f7f8fe055b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Using cached spacy-3.7.2-cp39-cp39-macosx_10_9_x86_64.whl (6.9 MB)\n",
      "Collecting weasel<0.4.0,>=0.1.0\n",
      "  Using cached weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./venv/lib/python3.9/site-packages (from spacy) (2.31.0)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl (133 kB)\n",
      "Requirement already satisfied: numpy>=1.19.0 in ./venv/lib/python3.9/site-packages (from spacy) (1.26.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4\n",
      "  Using cached pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.10-cp39-cp39-macosx_10_9_x86_64.whl (26 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8\n",
      "  Using cached thinc-8.2.1-cp39-cp39-macosx_10_9_x86_64.whl (876 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in ./venv/lib/python3.9/site-packages (from spacy) (4.66.1)\n",
      "Collecting typer<0.10.0,>=0.3.0\n",
      "  Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.8-cp39-cp39-macosx_10_9_x86_64.whl (42 kB)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.9/site-packages (from spacy) (58.1.0)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Using cached wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in ./venv/lib/python3.9/site-packages (from spacy) (6.4.0)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.8-cp39-cp39-macosx_10_9_x86_64.whl (493 kB)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from spacy) (23.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./venv/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.8.0)\n",
      "Collecting pydantic-core==2.14.5\n",
      "  Using cached pydantic_core-2.14.5-cp39-cp39-macosx_10_7_x86_64.whl (1.9 MB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Using cached confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Using cached blis-0.7.11-cp39-cp39-macosx_10_9_x86_64.whl (6.1 MB)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in ./venv/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0\n",
      "  Using cached cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, pydantic-core, murmurhash, langcodes, cloudpathlib, catalogue, blis, annotated-types, srsly, pydantic, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed annotated-types-0.6.0 blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 pydantic-2.5.2 pydantic-core-2.14.5 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b633801-29ce-48be-9774-31e3894ef9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.8.2-cp39-cp39-macosx_10_12_x86_64.whl (7.6 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.46.0-cp39-cp39-macosx_10_9_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.21 in ./venv/lib/python3.9/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting importlib-resources>=3.2.0\n",
      "  Using cached importlib_resources-6.1.1-py3-none-any.whl (33 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl (257 kB)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Using cached kiwisolver-1.4.5-cp39-cp39-macosx_10_9_x86_64.whl (68 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, importlib-resources, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.46.0 importlib-resources-6.1.1 kiwisolver-1.4.5 matplotlib-3.8.2 pyparsing-3.1.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9b4c45d-f8ec-4a32-a43d-8ad863247386",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.9.2-cp39-cp39-macosx_10_9_x86_64.whl (161 kB)\n",
      "Requirement already satisfied: numpy>=1.6.1 in ./venv/lib/python3.9/site-packages (from wordcloud) (1.26.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.9/site-packages (from wordcloud) (3.8.2)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.9/site-packages (from wordcloud) (10.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (6.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (3.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.9/site-packages (from matplotlib->wordcloud) (4.46.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa4473cf-ab2c-4608-aad8-ee7e5fe7b181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in ./venv/lib/python3.9/site-packages (from sentence_transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from sentence_transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./venv/lib/python3.9/site-packages (from sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in ./venv/lib/python3.9/site-packages (from sentence_transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from sentence_transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.9/site-packages (from sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.9/site-packages (from sentence_transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in ./venv/lib/python3.9/site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.99-cp39-cp39-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in ./venv/lib/python3.9/site-packages (from sentence_transformers) (0.19.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.8.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.2)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.13.1)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./venv/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./venv/lib/python3.9/site-packages (from torchvision->sentence_transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Using legacy 'setup.py install' for sentence_transformers, since package 'wheel' is not installed.\n",
      "Installing collected packages: sentencepiece, sentence_transformers\n",
      "  Running setup.py install for sentence_transformers ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e92b747e-815d-4969-9a63-dc566768698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext\n",
      "  Downloading torchtext-0.16.1-cp39-cp39-macosx_10_13_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting torchdata==0.7.1\n",
      "  Downloading torchdata-0.7.1-cp39-cp39-macosx_10_13_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch==2.1.1 in ./venv/lib/python3.9/site-packages (from torchtext) (2.1.1)\n",
      "Requirement already satisfied: requests in ./venv/lib/python3.9/site-packages (from torchtext) (2.31.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.9/site-packages (from torchtext) (1.26.2)\n",
      "Requirement already satisfied: tqdm in ./venv/lib/python3.9/site-packages (from torchtext) (4.66.1)\n",
      "Requirement already satisfied: filelock in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (4.8.0)\n",
      "Requirement already satisfied: fsspec in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (2023.10.0)\n",
      "Requirement already satisfied: jinja2 in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (3.1.2)\n",
      "Requirement already satisfied: networkx in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (3.2.1)\n",
      "Requirement already satisfied: sympy in ./venv/lib/python3.9/site-packages (from torch==2.1.1->torchtext) (1.12)\n",
      "Requirement already satisfied: urllib3>=1.25 in ./venv/lib/python3.9/site-packages (from torchdata==0.7.1->torchtext) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.9/site-packages (from requests->torchtext) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.9/site-packages (from requests->torchtext) (2023.11.17)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.9/site-packages (from requests->torchtext) (3.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./venv/lib/python3.9/site-packages (from jinja2->torch==2.1.1->torchtext) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./venv/lib/python3.9/site-packages (from sympy->torch==2.1.1->torchtext) (1.3.0)\n",
      "Installing collected packages: torchdata, torchtext\n",
      "Successfully installed torchdata-0.7.1 torchtext-0.16.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the '/Users/andriy/Desktop/Project_NLP/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b33e94b2-4a32-46bf-867d-8c7846ece244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification,Trainer, TrainingArguments\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import datasets\n",
    "from nltk import tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4b54b2-3bf1-4801-95c4-972ad7cc3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import tokenize\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, TimeSeriesSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from tqdm import tqdm\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from copy import deepcopy\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertModel, pipeline, get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.backends.cuda.deterministic = True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ef33993-c385-452a-b9b0-ab75dca4e91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news.csv                   \u001b[1m\u001b[36mtsn\u001b[m\u001b[m\n",
      "scraping.ipynb             \u001b[1m\u001b[36munian\u001b[m\u001b[m\n",
      "transformer_modeling.ipynb \u001b[1m\u001b[36mvenv\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d6f66bb-6d9d-48c0-a004-ab2b97d735de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"/Users/andriy/Desktop/Project_NLP/ukr-news\", index=False)\n",
    "df = pd.read_csv(\"/Users/andriy/Desktop/Project_NLP/ukr-news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66859460-a5c2-4474-b42c-0515ed03d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['economic', 'health', 'polit', 'science', 'war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adaef706-d6e7-47e2-9d04-824801833ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['category'].isin(categories)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "311053be-4077-4ffe-90e6-c1f663de953d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>Епічний кінець: вчені розповіли, як помре Земля</td>\n",
       "      <td>Сонце поглине Землю під час наближення до заве...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>Чому вимерли динозаври: штучний інтелект дав в...</td>\n",
       "      <td>Палеонтологи стверджують, що основною причиною...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>У Британії розкопали фундамент 1400-річного яз...</td>\n",
       "      <td>У Британії данському графстві Саффолк археолог...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>До Землі наблизиться небезпечний астероїд: що ...</td>\n",
       "      <td>У середу, 6 грудня, поблизу Землі пролетить ас...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2268</th>\n",
       "      <td>У ПАР знайшли тваринку, яка вважалася вимерлою...</td>\n",
       "      <td>Вперше за майже 100 років у Південній Африці з...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22265</th>\n",
       "      <td>Україна збиватиме ракетами російські дрони з К...</td>\n",
       "      <td>Українські військові мають намір збивати росій...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22266</th>\n",
       "      <td>Окупанти прийняли \"закон\" про держкордон \"ДНР\"...</td>\n",
       "      <td>Так звана «Народна Рада» самопроголошеної «ДНР...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22267</th>\n",
       "      <td>Україна провела військові маневри з протидесан...</td>\n",
       "      <td>Українські військові на одному з полігонів бой...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22268</th>\n",
       "      <td>Бойовики зазнали масштабних втрат на Донбасі</td>\n",
       "      <td>За тиждень з 22 по 28 листопада 2019 року, втр...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22269</th>\n",
       "      <td>Бойовики на Донеччині обстріляли українських в...</td>\n",
       "      <td>28 листопада бойовики на Донбасі 9 разів поруш...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18521 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "2264     Епічний кінець: вчені розповіли, як помре Земля   \n",
       "2265   Чому вимерли динозаври: штучний інтелект дав в...   \n",
       "2266   У Британії розкопали фундамент 1400-річного яз...   \n",
       "2267   До Землі наблизиться небезпечний астероїд: що ...   \n",
       "2268   У ПАР знайшли тваринку, яка вважалася вимерлою...   \n",
       "...                                                  ...   \n",
       "22265  Україна збиватиме ракетами російські дрони з К...   \n",
       "22266  Окупанти прийняли \"закон\" про держкордон \"ДНР\"...   \n",
       "22267  Україна провела військові маневри з протидесан...   \n",
       "22268       Бойовики зазнали масштабних втрат на Донбасі   \n",
       "22269  Бойовики на Донеччині обстріляли українських в...   \n",
       "\n",
       "                                                    text category  \n",
       "2264   Сонце поглине Землю під час наближення до заве...  science  \n",
       "2265   Палеонтологи стверджують, що основною причиною...  science  \n",
       "2266   У Британії данському графстві Саффолк археолог...  science  \n",
       "2267   У середу, 6 грудня, поблизу Землі пролетить ас...  science  \n",
       "2268   Вперше за майже 100 років у Південній Африці з...  science  \n",
       "...                                                  ...      ...  \n",
       "22265  Українські військові мають намір збивати росій...      war  \n",
       "22266  Так звана «Народна Рада» самопроголошеної «ДНР...      war  \n",
       "22267  Українські військові на одному з полігонів бой...      war  \n",
       "22268  За тиждень з 22 по 28 листопада 2019 року, втр...      war  \n",
       "22269  28 листопада бойовики на Донбасі 9 разів поруш...      war  \n",
       "\n",
       "[18521 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940894d2-373c-4f11-9fa2-97aedb8483fa",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc27edbe-0499-4df2-9d05-9c3764f9d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['category']\n",
    "\n",
    "# Perform train-test split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create new DataFrames with both text data and labels\n",
    "train_df = pd.DataFrame({'text': train_data, 'label': train_labels})\n",
    "test_df = pd.DataFrame({'text': test_data, 'label': test_labels})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "581c8411-649a-4c7a-b7fb-22994e2fd3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17943</th>\n",
       "      <td>Станом на 5 грудня Київ та ще сім областей \"че...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15273</th>\n",
       "      <td>Китай охопила нова епідемія / фото REUTERS Кит...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>У Києві 8 квітня завершується опалювальний сез...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>Більшість схиляється до того, що коронавірус в...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Аграрии начали посевную кампанию, которая обой...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15033</th>\n",
       "      <td>Манекен одного з головних персонажів всесвіту ...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15713</th>\n",
       "      <td>В Україні хочуть легалізувати медичний канабіс...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>Российские войска и вскормленные Кремлем боеви...</td>\n",
       "      <td>economic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>Команда вчених пропонує нове пояснення деяких ...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19544</th>\n",
       "      <td>Пригожин спростував заяви Кремля про війну РФ ...</td>\n",
       "      <td>war</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14816 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "17943  Станом на 5 грудня Київ та ще сім областей \"че...    health\n",
       "15273  Китай охопила нова епідемія / фото REUTERS Кит...    health\n",
       "4298   У Києві 8 квітня завершується опалювальний сез...  economic\n",
       "15970  Більшість схиляється до того, що коронавірус в...    health\n",
       "8409   Аграрии начали посевную кампанию, которая обой...  economic\n",
       "...                                                  ...       ...\n",
       "15033  Манекен одного з головних персонажів всесвіту ...   science\n",
       "15713  В Україні хочуть легалізувати медичний канабіс...    health\n",
       "9139   Российские войска и вскормленные Кремлем боеви...  economic\n",
       "3124   Команда вчених пропонує нове пояснення деяких ...    health\n",
       "19544  Пригожин спростував заяви Кремля про війну РФ ...       war\n",
       "\n",
       "[14816 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6db99758-5187-4679-b308-d55340123a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(train_df['label'], prefix='is_')\n",
    "dummy_df = dummy_df.astype(int)\n",
    "train_df = pd.concat([train_df, dummy_df], axis=1)\n",
    "\n",
    "dummy_df = pd.get_dummies(test_df['label'], prefix='is_')\n",
    "dummy_df = dummy_df.astype(int)\n",
    "test_df = pd.concat([test_df, dummy_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4d6c004-3b0f-4091-b070-b5e1063d1a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>is__economic</th>\n",
       "      <th>is__health</th>\n",
       "      <th>is__polit</th>\n",
       "      <th>is__science</th>\n",
       "      <th>is__war</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17943</th>\n",
       "      <td>Станом на 5 грудня Київ та ще сім областей \"че...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15273</th>\n",
       "      <td>Китай охопила нова епідемія / фото REUTERS Кит...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4298</th>\n",
       "      <td>У Києві 8 квітня завершується опалювальний сез...</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15970</th>\n",
       "      <td>Більшість схиляється до того, що коронавірус в...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8409</th>\n",
       "      <td>Аграрии начали посевную кампанию, которая обой...</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15033</th>\n",
       "      <td>Манекен одного з головних персонажів всесвіту ...</td>\n",
       "      <td>science</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15713</th>\n",
       "      <td>В Україні хочуть легалізувати медичний канабіс...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9139</th>\n",
       "      <td>Российские войска и вскормленные Кремлем боеви...</td>\n",
       "      <td>economic</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>Команда вчених пропонує нове пояснення деяких ...</td>\n",
       "      <td>health</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19544</th>\n",
       "      <td>Пригожин спростував заяви Кремля про війну РФ ...</td>\n",
       "      <td>war</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14816 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label  \\\n",
       "17943  Станом на 5 грудня Київ та ще сім областей \"че...    health   \n",
       "15273  Китай охопила нова епідемія / фото REUTERS Кит...    health   \n",
       "4298   У Києві 8 квітня завершується опалювальний сез...  economic   \n",
       "15970  Більшість схиляється до того, що коронавірус в...    health   \n",
       "8409   Аграрии начали посевную кампанию, которая обой...  economic   \n",
       "...                                                  ...       ...   \n",
       "15033  Манекен одного з головних персонажів всесвіту ...   science   \n",
       "15713  В Україні хочуть легалізувати медичний канабіс...    health   \n",
       "9139   Российские войска и вскормленные Кремлем боеви...  economic   \n",
       "3124   Команда вчених пропонує нове пояснення деяких ...    health   \n",
       "19544  Пригожин спростував заяви Кремля про війну РФ ...       war   \n",
       "\n",
       "       is__economic  is__health  is__polit  is__science  is__war  \n",
       "17943             0           1          0            0        0  \n",
       "15273             0           1          0            0        0  \n",
       "4298              1           0          0            0        0  \n",
       "15970             0           1          0            0        0  \n",
       "8409              1           0          0            0        0  \n",
       "...             ...         ...        ...          ...      ...  \n",
       "15033             0           0          0            1        0  \n",
       "15713             0           1          0            0        0  \n",
       "9139              1           0          0            0        0  \n",
       "3124              0           1          0            0        0  \n",
       "19544             0           0          0            0        1  \n",
       "\n",
       "[14816 rows x 7 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "909b6563-3e7b-4023-992e-20ca2cd69eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'is__economic', 'is__health', 'is__polit',\n",
       "       'is__science', 'is__war'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6cb8c7f-6b4f-49b5-b1c1-580e86c3683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMNS = ['is__economic', 'is__health', 'is__polit',\n",
    "       'is__science', 'is__war']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f12cee7e-6a08-4d2a-885f-6f741c27deb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/andriy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "def collapse_dots(input):\n",
    "    # Collapse sequential dots\n",
    "    input = re.sub(\"\\.+\", \".\", input)\n",
    "    # Collapse dots separated by whitespaces\n",
    "    all_collapsed = False\n",
    "    while not all_collapsed:\n",
    "        output = re.sub(r\"\\.(( )*)\\.\", \".\", input)\n",
    "        all_collapsed = input == output\n",
    "        input = output\n",
    "    return output\n",
    "\n",
    "def process_text(input):\n",
    "    if isinstance(input, str):\n",
    "        input = \" \".join(tokenize.sent_tokenize(input))\n",
    "        input = re.sub(r\"http\\S+\", \"\", input)\n",
    "        input = re.sub(r\"\\n+\", \". \", input)\n",
    "        for symb in [\"!\", \",\", \":\", \";\", \"?\"]:\n",
    "            input = re.sub(rf\"\\{symb}\\.\", symb, input)\n",
    "        input = re.sub(r\"#\\S+\", \"\", input)\n",
    "        input = collapse_dots(input)\n",
    "        input = input.strip()\n",
    "        # input = input.lower()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a722c175-29e8-4528-9594-1f45174e2089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['clean_text'] = train_df['text'].apply(process_text)\n",
    "test_df['clean_text'] = test_df['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "712f780f-2a95-4926-86ce-49a5d91918ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"strat_feature\"] = train_df[TARGET_COLUMNS].apply(\n",
    "    lambda x: reduce(lambda x, y: str(x) + str(y), x), axis=1\n",
    ")\n",
    "small_strat_groups = train_df[\"strat_feature\"].value_counts()[\n",
    "    train_df[\"strat_feature\"].value_counts() < 5\n",
    "].index\n",
    "train_df.loc[train_df[\"strat_feature\"].isin(small_strat_groups), \"strat_feature\"] = \"-1\"\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds_train_test_ids = [el for el in skf.split(train_df, train_df[\"strat_feature\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9aedcf62-6f8e-49f2-8558-dfafdca7ada7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_metric(y_true, y_pred, verbose=True):\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    class_roc_aucs = [roc_auc_score(y_true[:,i], y_pred[:,i]) for i in range(y_pred.shape[1])]\n",
    "    if verbose:\n",
    "        for ra, tgt_col in zip(class_roc_aucs, TARGET_COLUMNS):\n",
    "            print(f\"{tgt_col} Roc Auc: {ra}\")\n",
    "        print(f\"Result Roc Auc: {np.mean(class_roc_aucs)}\")\n",
    "    return class_roc_aucs, np.mean(class_roc_aucs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fad24ec7-8429-4e77-83cf-ab5cbf996bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at youscan/ukr-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"youscan/ukr-roberta-base\", max_length = 512)\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"youscan/ukr-roberta-base\",\n",
    "    num_labels=len(TARGET_COLUMNS),\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ee72fa6-ab1a-4ca5-81de-eef305048964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dataset import TextDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e7998a5-5ccc-433b-b91b-3f0a192bc0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing Tokenized ids ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (4289 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized ids precomputed!\n"
     ]
    }
   ],
   "source": [
    "train_torch_dataset = TextDataset(\n",
    "    texts=train_df[\"clean_text\"].to_list(),\n",
    "    targets=train_df[TARGET_COLUMNS].values,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96e980e6-f095-4405-ba72-e939928fb7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_loop(\n",
    "    dataloader,\n",
    "    inp_model,\n",
    "    inp_optimizer,\n",
    "    inp_criterion,\n",
    "    inp_scheduler=None,\n",
    "    mode=\"train\",\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    if mode == \"train\":\n",
    "        inp_model.train()\n",
    "    else:\n",
    "        inp_model.eval()\n",
    "    all_predicted_label = []\n",
    "    all_losses = []\n",
    "    all_targets = []\n",
    "    # We need this context in order to control gradient computation\n",
    "    # mode == True - gradient will NOT be computed, mode == False - gradient will be computed\n",
    "    with torch.inference_mode(mode=(mode != \"train\")):\n",
    "        for text in tqdm(dataloader):\n",
    "            text = {k:v.to(device) for k,v in text.items()}\n",
    "            label = text.pop(\"target\")\n",
    "            if mode == \"train\":\n",
    "                inp_optimizer.zero_grad()\n",
    "            # 1.1 Compute Forward path\n",
    "            predicted_label = inp_model(**text).logits\n",
    "            # 1.2 Compute Cost function (part of Forward path)\n",
    "            loss = inp_criterion(predicted_label, label)\n",
    "            if mode == \"train\":\n",
    "                loss.mean().backward()\n",
    "                inp_optimizer.step()\n",
    "                if inp_scheduler is not None:\n",
    "                    inp_scheduler.step()\n",
    "\n",
    "            # Accumulate stats\n",
    "            # We receive logits and we have to transform them into `probs`. That is why sigmoid is used\n",
    "            all_predicted_label.append(torch.sigmoid(predicted_label.detach()).cpu().numpy())\n",
    "            all_losses.append(loss.detach().cpu().numpy())\n",
    "            all_targets.append(label.detach().cpu().numpy())\n",
    "    all_predicted_label = np.concatenate(all_predicted_label)\n",
    "    all_losses = np.concatenate(all_losses)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "\n",
    "    return all_predicted_label, all_losses, all_targets\n",
    "\n",
    "def print_losses(input):\n",
    "    for cls_idx, cls_name in enumerate(TARGET_COLUMNS):\n",
    "        print(f\"{cls_name} BCE loss: {input[:,cls_idx].mean()}\")\n",
    "    print(f\"Result BCE loss: {input.mean()}\")\n",
    "\n",
    "def visualise_lr_scheduling(lr_scheduler_from_opt, n_steps, verbose=True, lr=1e-3):\n",
    "    t_opt = torch.optim.SGD([torch.tensor(1)], lr=lr)\n",
    "    t_sched = lr_scheduler_from_opt(t_opt)\n",
    "    lrs = []\n",
    "    for i in range(n_steps):\n",
    "        t_opt.step()\n",
    "        lrs.append(t_sched.get_lr()[0])\n",
    "        t_sched.step()\n",
    "\n",
    "    if verbose:\n",
    "        plt.title(\"Learning Rate Schedule\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Learning Rate\")\n",
    "        plt.plot(lrs)\n",
    "        plt.show()\n",
    "\n",
    "    return lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7a6ec0d6-97d1-4141-90e1-8491e83b8104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at youscan/ukr-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "nn_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"youscan/ukr-roberta-base\",\n",
    "    num_labels=len(TARGET_COLUMNS),\n",
    "    ignore_mismatched_sizes=True\n",
    ").to(\"cpu\")\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': nn_model.roberta.parameters(), \"lr\": 1e-5},\n",
    "    {'params': nn_model.classifier.parameters(), \"lr\": 1e-3},\n",
    "], weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fbd66a77-5639-4ee4-ac7a-b6a922971795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing Tokenized ids ...\n",
      "Tokenized ids precomputed!\n",
      "Precomputing Tokenized ids ...\n",
      "Tokenized ids precomputed!\n"
     ]
    }
   ],
   "source": [
    "train_torch_dataset = TextDataset(\n",
    "    texts=train_df.iloc[folds_train_test_ids[0][0]][\"clean_text\"].to_list(),\n",
    "    targets=train_df.iloc[folds_train_test_ids[0][0]][TARGET_COLUMNS].values,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    ")\n",
    "train_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    train_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "valid_torch_dataset = TextDataset(\n",
    "    texts=train_df.iloc[folds_train_test_ids[0][1]][\"clean_text\"].to_list(),\n",
    "    targets=train_df.iloc[folds_train_test_ids[0][1]][TARGET_COLUMNS].values,\n",
    "    dataset_tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    trim_policy=\"first\"\n",
    ")\n",
    "valid_torch_dataloader = torch.utils.data.DataLoader(\n",
    "    valid_torch_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=8,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "905b5d7a-b8dc-422f-a936-40730851c9a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "# Here is an example of scheduler, which udates after each iteration (batch) , NOT after each epoch\n",
    "# Also it has 2\n",
    "visualise_lr_scheduling(\n",
    "    lr_scheduler_from_opt=lambda opt: get_linear_schedule_with_warmup(\n",
    "        optimizer=opt,\n",
    "        num_warmup_steps=int(0.05*len(train_torch_dataloader)*n_epochs),\n",
    "        num_training_steps=len(train_torch_dataloader)*n_epochs\n",
    "    ),\n",
    "    n_steps=len(train_torch_dataloader)*n_epochs,\n",
    "    lr=2e-5\n",
    ")\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=int(0.05*len(train_torch_dataloader)*n_epochs),\n",
    "    num_training_steps=len(train_torch_dataloader)*n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1fa0bbb0-40a8-4e57-87f1-4401bdfa010b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "Train phase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                 | 3/370 [09:16<17:51:39, 175.20s/it]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fcf32b75820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/andriy/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/andriy/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/andriy/opt/anaconda3/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/andriy/opt/anaconda3/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/andriy/opt/anaconda3/lib/python3.9/multiprocessing/connection.py\", line 936, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/andriy/opt/anaconda3/lib/python3.9/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "  1%|▋                                                                                 | 3/370 [09:39<19:41:11, 193.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[80], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 1.1 Iterate over all train dataset and update model weights\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain phase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m train_epoch_labels, train_epoch_losses, train_epoch_targets \u001b[38;5;241m=\u001b[39m \u001b[43mtorch_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_torch_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_criterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43minp_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 1.2 Compute and print train metrics\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain metrics\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[70], line 26\u001b[0m, in \u001b[0;36mtorch_loop\u001b[0;34m(dataloader, inp_model, inp_optimizer, inp_criterion, inp_scheduler, mode, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m     inp_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 1.1 Compute Forward path\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43minp_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 1.2 Compute Cost function (part of Forward path)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m inp_criterion(predicted_label, label)\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:1198\u001b[0m, in \u001b[0;36mRobertaForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1198\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroberta\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1209\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1210\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:455\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    453\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 455\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/pytorch_utils.py:241\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:467\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 467\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    468\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/transformers/models/roberta/modeling_roberta.py:365\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/Project_NLP/venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_all_epoch_labels = []\n",
    "train_all_epoch_losses = []\n",
    "train_all_epoch_targets = []\n",
    "valid_all_epoch_labels = []\n",
    "valid_all_epoch_losses = []\n",
    "valid_all_epoch_targets = []\n",
    "valid_roc_aucs = []\n",
    "train_roc_aucs = []\n",
    "\n",
    "best_metric = np.inf\n",
    "best_model_state_dict = None\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Starting Epoch {epoch}\")\n",
    "    # 1.1 Iterate over all train dataset and update model weights\n",
    "    print(\"Train phase\")\n",
    "    train_epoch_labels, train_epoch_losses, train_epoch_targets = torch_loop(\n",
    "        dataloader=train_torch_dataloader,\n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        inp_scheduler=scheduler,\n",
    "        device=\"cpu\",\n",
    "        mode=\"train\"\n",
    "    )\n",
    "    # 1.2 Compute and print train metrics\n",
    "    print(\"Train metrics\")\n",
    "    train_roc_auc = mean_squared_error(\n",
    "        train_epoch_targets,\n",
    "        train_epoch_labels\n",
    "    )\n",
    "    print(train_roc_auc)\n",
    "    print(\"Train BCE losses\")\n",
    "    print_losses(train_epoch_losses)\n",
    "    # 2.1 Iterate over all valid dataset and compute predictions\n",
    "    print(\"Valid phase\")\n",
    "    valid_epoch_labels, valid_epoch_losses, valid_epoch_targets = torch_loop(\n",
    "        dataloader=valid_torch_dataloader,\n",
    "        inp_model=nn_model,\n",
    "        inp_optimizer=optimizer,\n",
    "        inp_criterion=criterion,\n",
    "        device=\"cpu\",\n",
    "        mode=\"eval\"\n",
    "    )\n",
    "    # 2.2 Compute and print valid metrics\n",
    "    print(\"Valid metrics\")\n",
    "    valid_roc_auc = mean_squared_error(\n",
    "        valid_epoch_targets,\n",
    "        valid_epoch_labels\n",
    "    )\n",
    "    print(valid_roc_auc)\n",
    "    print(\"Valid BCE losses\")\n",
    "    print_losses(valid_epoch_losses)\n",
    "    # # 3. Update learning rate (if needed)\n",
    "    # scheduler.step(valid_roc_auc)\n",
    "    # 4. Save best model\n",
    "    if valid_roc_auc < best_metric:\n",
    "        best_metric = valid_roc_auc\n",
    "        best_model_state_dict = deepcopy(nn_model.state_dict())\n",
    "    # 5. Accumulate all stats\n",
    "    train_all_epoch_labels.append(train_epoch_labels)\n",
    "    train_all_epoch_losses.append(train_epoch_losses)\n",
    "    train_all_epoch_targets.append(train_epoch_targets)\n",
    "    valid_all_epoch_labels.append(valid_epoch_labels)\n",
    "    valid_all_epoch_losses.append(valid_epoch_losses)\n",
    "    valid_all_epoch_targets.append(valid_epoch_targets)\n",
    "    valid_roc_aucs.append(valid_roc_auc)\n",
    "    train_roc_aucs.append(train_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39250894-cee8-4d27-8bd8-7c80f03b97b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
